{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ioanamazilu/PycharmProjects/quant_nli/data/equate\n"
     ]
    }
   ],
   "source": [
    "root_path = os.path.dirname(os.path.dirname(os.getcwd()))  # go 3 back, on the same level with the \"data\" directory\n",
    "\n",
    "datasets_path = os.path.join(root_path, \"data\", \"equate\")\n",
    "print(datasets_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWPNLI\n",
      "Dataset size pre-deduplication: 722\n",
      "0 duplicates\n",
      "NewsNLI\n",
      "Dataset size pre-deduplication: 968\n",
      "5 duplicates\n",
      "5 duplicates (with label)\n",
      "5 duplicates (lowercase)\n",
      "Dataset size post-deduplication: 963\n",
      "RedditNLI\n",
      "Dataset size pre-deduplication: 250\n",
      "3 duplicates\n",
      "3 duplicates (with label)\n",
      "3 duplicates (lowercase)\n",
      "Dataset size post-deduplication: 247\n",
      "RTE_Quant\n",
      "Dataset size pre-deduplication: 166\n",
      "1 duplicates\n",
      "1 duplicates (with label)\n",
      "1 duplicates (lowercase)\n",
      "Dataset size post-deduplication: 165\n",
      "StressTest\n",
      "Dataset size pre-deduplication: 7596\n",
      "643 duplicates\n",
      "643 duplicates (with label)\n",
      "649 duplicates (lowercase)\n",
      "Dataset size post-deduplication: 6947\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.join(datasets_path, \"01_duplicates\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(datasets_path, \"01_deduplicated\"), exist_ok=True)\n",
    "for dataset in [\"AWPNLI\", \"NewsNLI\", \"RedditNLI\", \"RTE_Quant\", \"StressTest\"]:\n",
    "    print(dataset)\n",
    "    df = pd.read_csv(os.path.join(datasets_path, f\"{dataset}.csv\"))\n",
    "    print(f\"Dataset size pre-deduplication: {df.shape[0]}\")\n",
    "\n",
    "    duplicates = df[df.duplicated(subset=[\"premise\", \"hypothesis\"])].shape[0]\n",
    "    print(f\"{duplicates} duplicates\")\n",
    "    if duplicates > 0:\n",
    "        duplicates_add_label = df[df.duplicated(subset=[\"premise\", \"hypothesis\", \"label\"])].shape[0]\n",
    "        print(f\"{duplicates_add_label} duplicates (with label)\")\n",
    "\n",
    "        # Turn the premise and hypothesis to lowercase, to ensure we do a case-insensitive check for duplicates as well\n",
    "        df[\"premise_lower\"] = df[\"premise\"].str.lower()\n",
    "        df[\"hypothesis_lower\"] = df[\"hypothesis\"].str.lower()\n",
    "\n",
    "        duplicates_lowercase = df[df.duplicated(subset=[\"premise_lower\", \"hypothesis_lower\"])].shape[0]\n",
    "        print(f\"{duplicates_lowercase} duplicates (lowercase)\")\n",
    "\n",
    "        duplicates = df[df.duplicated(subset=[\"premise_lower\", \"hypothesis_lower\"])][[\"premise\", \"hypothesis\", \"label\", \"sample_index\"]]\n",
    "\n",
    "        duplicates.to_csv(os.path.join(datasets_path, \"01_duplicates\", f\"duplicates_{dataset}.csv\"), index=False)\n",
    "\n",
    "        deduplicated_df = df.drop_duplicates(subset=[\"premise_lower\", \"hypothesis_lower\"], ignore_index=True)\n",
    "\n",
    "        deduplicated_df[[\"premise\", \"hypothesis\", \"label\", \"sample_index\"]].to_csv(os.path.join(datasets_path, \"01_deduplicated\", f\"{dataset}.csv\"), index=False)\n",
    "\n",
    "        print(f\"Dataset size post-deduplication: {deduplicated_df.shape[0]}\")\n",
    "    else:\n",
    "        df[[\"premise\", \"hypothesis\", \"label\", \"sample_index\"]].to_csv(os.path.join(datasets_path, \"01_deduplicated\", f\"{dataset}.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
