{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# [\"AWPNLI\", \"RedditNLI\", \"StressTest\", \"RTE_Quant\", \"NewsNLI\"]\n",
    "dataset = \"RTE_Quant\"\n",
    "root_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "results_path = os.path.join(root_path, \"data\", \"equate_labelled\", f\"{dataset}_phase2.csv\")\n",
    "os.makedirs(os.path.join(root_path, \"data\", \"equate_labelled\", \"processed\"), exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "   sample_index generated_label  error_message golden_label  \\\n0           575      entailment            NaN      neutral   \n1           914   contradiction            NaN      neutral   \n2           450      entailment            NaN   entailment   \n3           860         neutral            NaN      neutral   \n4           831         neutral            NaN      neutral   \n\n                                             premise  \\\n0  Peter Siebold, 43, was identified as the pilot...   \n1  Holder said the Justice Department is working ...   \n2  The nine were brought into Somali waters and t...   \n3  There are some additional 863 cancer cases amo...   \n4  The survey said 57% supported it going forward...   \n\n                                          hypothesis  \n0  Pilot who survived identified as Peter Siebold...  \n1  Ten Mexican nationals have been charged and se...  \n2  Nine people were brought into Somali waters, h...  \n3  There are at least 2,509 certified cancer case...  \n4  New CNN/ORC survey shows 57% of Americans supp...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_index</th>\n      <th>generated_label</th>\n      <th>error_message</th>\n      <th>golden_label</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>575</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>neutral</td>\n      <td>Peter Siebold, 43, was identified as the pilot...</td>\n      <td>Pilot who survived identified as Peter Siebold...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>914</td>\n      <td>contradiction</td>\n      <td>NaN</td>\n      <td>neutral</td>\n      <td>Holder said the Justice Department is working ...</td>\n      <td>Ten Mexican nationals have been charged and se...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>450</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>entailment</td>\n      <td>The nine were brought into Somali waters and t...</td>\n      <td>Nine people were brought into Somali waters, h...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>860</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>neutral</td>\n      <td>There are some additional 863 cancer cases amo...</td>\n      <td>There are at least 2,509 certified cancer case...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>831</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>neutral</td>\n      <td>The survey said 57% supported it going forward...</td>\n      <td>New CNN/ORC survey shows 57% of Americans supp...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.read_csv(results_path)\n",
    "res.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "(958, 6)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res.duplicated(subset=[\"sample_index\"])].shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# res = res.drop_duplicates(subset=['sample_index'], keep='first', ignore_index=True)\n",
    "# res.to_csv(results_path, index=False)\n",
    "# res.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do we have scripts that threw an error?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res['error_message'].notna()].shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(res[res['error_message'].notna()][\"sample_index\"].values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter out erroneous scripts, if any"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "valid_res = res[res[\"error_message\"].isna()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "golden_label\nentailment    0.504175\nneutral       0.495825\nName: proportion, dtype: float64"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res[\"golden_label\"].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "generated_label\nentailment       521\nneutral          382\ncontradiction     55\nName: count, dtype: int64"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res[\"generated_label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "if dataset == \"AWPNLI\":\n",
    "    valid_res = valid_res[valid_res[\"generated_label\"]!=\"neutral\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# valid_res[valid_res[\"generated_label\"]==\"contradiction\"].to_excel(\"NewsNLI_predicted_contradiction.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# # AWPNLI baselines\n",
    "# mb_baseline_accuracy = 0.50\n",
    "# rsb_baseline_accuracy = 0.50\n",
    "# rsb_baseline_f1_c = 0.5\n",
    "# rsb_baseline_f1_e = 0.5\n",
    "#\n",
    "# # RedditNLI baselines\n",
    "# mb_baseline_accuracy = 57.89\n",
    "# rsb_baseline_accuracy = 45.94\n",
    "# rsb_baseline_f1_e = 57.89\n",
    "# rsb_baseline_f1_n = 34.41\n",
    "# rsb_baseline_f1_n = 7.69\n",
    "#\n",
    "# # StressTest baselines\n",
    "# mb_baseline_accuracy = 0.33\n",
    "# rsb_baseline_accuracy = 0.33\n",
    "# rsb_baseline_f1_c = 0.33\n",
    "# rsb_baseline_f1_e = 0.33\n",
    "# rsb_baseline_f1_n = 0.33\n",
    "#\n",
    "# # NewsNLI baselines\n",
    "# mb_baseline_accuracy = 0\n",
    "# rsb_baseline_accuracy = 0\n",
    "# rsb_baseline_f1_c = 0\n",
    "# rsb_baseline_f1_e = 0\n",
    "#\n",
    "# # RTE_Quant baselines\n",
    "# mb_baseline_accuracy = 0\n",
    "# rsb_baseline_accuracy = 0\n",
    "# rsb_baseline_f1_c = 0\n",
    "# rsb_baseline_f1_e = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "if dataset in [\"RTE_Quant\", \"NewsNLI\"]:\n",
    "    # Creating masks based on conditions\n",
    "    convert_contradiction_to_neutral_mask = valid_res[\"generated_label\"] == \"contradiction\"\n",
    "\n",
    "    # Correctly assigning a new value using the combined mask with .loc\n",
    "    valid_res.loc[convert_contradiction_to_neutral_mask, \"generated_label\"] = \"neutral\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "696"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res[valid_res['golden_label'] == valid_res['generated_label']].shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7265135699373695"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=valid_res['golden_label'], y_pred=valid_res['generated_label'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  entailment       0.75      0.96      0.84        68\n",
      "     neutral       0.96      0.77      0.85        94\n",
      "\n",
      "    accuracy                           0.85       162\n",
      "   macro avg       0.85      0.86      0.85       162\n",
      "weighted avg       0.87      0.85      0.85       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=valid_res['golden_label'], y_pred=valid_res['generated_label']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "valid_res = valid_res[[\"sample_index\", \"premise\", \"hypothesis\", \"golden_label\", \"generated_label\"]].rename(columns={\"generated_label\": \"reference_label\"})\n",
    "valid_res.to_csv(os.path.join(root_path, \"data\", \"equate_labelled\", \"processed\", f\"{dataset}.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Only for RTE_Quant and NEWSNLI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "data": {
      "text/plain": "corrected_golden_label\nneutral          72\nentailment       68\ncontradiction    22\nName: count, dtype: int64"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid_res[valid_res[\"generated_label\"]==\"contradiction\"][[\"sample_index\", \"premise\", \"hypothesis\"]].to_excel(\"NewsNLI_predicted_contradiction.xlsx\")\n",
    "\n",
    "# target label is neutral, model labels as contradiction and manual inspection indicates contradiction as well  (only applicable to NewsNLI and RTE_Quant, which treat \"contradiction\" case as neutral)\n",
    "news_nli_corrected_labels_indices = [914, 736, 663, 749, 838, 605]\n",
    "mask_news = valid_res['sample_index'].isin(news_nli_corrected_labels_indices)\n",
    "\n",
    "rte_quant_corrected_labels_indices = [118, 128, 98, 7, 21, 54, 147, 20, 30, 155, 52, 95, 120, 72, 150, 57, 111, 26, 115, 58, 4, 18]\n",
    "mask_rte = valid_res['sample_index'].isin(rte_quant_corrected_labels_indices)\n",
    "\n",
    "valid_res['corrected_golden_label'] = valid_res[\"golden_label\"]\n",
    "valid_res.loc[mask_news, 'corrected_golden_label'] = 'contradiction'\n",
    "valid_res[\"corrected_golden_label\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### First consider the case when we correct the reference label through manual verification. Now the dataset is framed as a 3-way decision."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "data": {
      "text/plain": "corrected_golden_label\nneutral          0.444444\nentailment       0.419753\ncontradiction    0.135802\nName: proportion, dtype: float64"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res[\"corrected_golden_label\"].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "134"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res[valid_res['corrected_golden_label'] == valid_res['generated_label']].shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8271604938271605"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=valid_res['corrected_golden_label'], y_pred=valid_res['generated_label'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.85      1.00      0.92        22\n",
      "   entailment       0.75      0.96      0.84        68\n",
      "      neutral       0.96      0.65      0.78        72\n",
      "\n",
      "     accuracy                           0.83       162\n",
      "    macro avg       0.85      0.87      0.84       162\n",
      " weighted avg       0.85      0.83      0.82       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=valid_res['corrected_golden_label'], y_pred=valid_res['generated_label']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now consider the case when we consider \"contradiction\" as neutral label, to remain consistent with the results from other papers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "valid_res[\"modified_label\"] = valid_res[\"generated_label\"].apply(lambda label: label if label == \"entailment\" else \"neutral\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "golden_label\nentailment    0.504175\nneutral       0.495825\nName: proportion, dtype: float64"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res['golden_label'].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "696"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res[valid_res['golden_label'] == valid_res['modified_label']].shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7265135699373695"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=valid_res['golden_label'], y_pred=valid_res['modified_label'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  entailment       0.71      0.77      0.74       483\n",
      "     neutral       0.74      0.68      0.71       475\n",
      "\n",
      "    accuracy                           0.73       958\n",
      "   macro avg       0.73      0.73      0.73       958\n",
      "weighted avg       0.73      0.73      0.73       958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=valid_res['golden_label'], y_pred=valid_res['modified_label']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "save_data = valid_res[[\"sample_index\", \"premise\", \"hypothesis\", \"golden_label\", \"modified_label\"]].rename(columns={\"modified_label\": \"reference_label\"})\n",
    "\n",
    "save_data.to_csv(os.path.join(root_path, \"data\", \"equate_labelled\", \"processed\", f\"{dataset}.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "     sample_index       label  error_message golden_label\n134             0     neutral            NaN      neutral\n148             1  entailment            NaN      neutral\n8               2  entailment            NaN      neutral\n11              3  entailment            NaN   entailment\n140             4     neutral            NaN      neutral\n145             5  entailment            NaN      neutral\n5               6  entailment            NaN   entailment\n17              7     neutral            NaN      neutral\n39              8  entailment            NaN   entailment\n54              9  entailment            NaN   entailment",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_index</th>\n      <th>label</th>\n      <th>error_message</th>\n      <th>golden_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>134</th>\n      <td>0</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>1</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>4</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>5</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>7</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>8</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>9</td>\n      <td>entailment</td>\n      <td>NaN</td>\n      <td>entailment</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_res.sort_values(by=\"sample_index\").head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 2,\n 5,\n 10,\n 20,\n 26,\n 31,\n 37,\n 39,\n 42,\n 47,\n 54,\n 55,\n 65,\n 66,\n 77,\n 81,\n 82,\n 87,\n 89,\n 92,\n 93,\n 94,\n 103,\n 106,\n 109,\n 110,\n 139,\n 142,\n 151,\n 162]"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_samples_indices = sorted(valid_res[valid_res[\"generated_label\"] != valid_res[\"golden_label\"]][\"sample_index\"].unique())\n",
    "misclassified_samples_indices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AWPNLI:\n",
    "approx issues: 58, 60, 500, 602, 614, 648, 686\n",
    "ambiguity: 62, 82, 304, 305, 482\n",
    "wrong label in equate: 107, 106, 109, 138, 550, 674\n",
    "RedditNLI:\n",
    "not sure how to correct: 24,\n",
    "wrong label: 36\n",
    "RTE_Quant:\n",
    "wrong label: 26, 31\n",
    "not sure how to correct: 142"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "31"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(misclassified_samples_indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "[0,\n 1,\n 2,\n 3,\n 4,\n 6,\n 7,\n 8,\n 9,\n 10,\n 12,\n 13,\n 14,\n 15,\n 16,\n 18,\n 19,\n 20,\n 21,\n 22,\n 24,\n 26,\n 28,\n 29,\n 30,\n 32,\n 34,\n 35,\n 36,\n 38,\n 39,\n 40,\n 41,\n 42,\n 44,\n 46,\n 47,\n 50,\n 51,\n 52,\n 53,\n 54,\n 55,\n 56,\n 57,\n 58,\n 60,\n 62,\n 64,\n 66,\n 67,\n 68,\n 70,\n 71,\n 72,\n 73,\n 74,\n 76,\n 78,\n 79,\n 80,\n 82,\n 84,\n 86,\n 88,\n 90,\n 92,\n 93,\n 94,\n 96,\n 97,\n 98,\n 99,\n 100,\n 101,\n 102,\n 103,\n 104,\n 106,\n 108,\n 110,\n 111,\n 112,\n 113,\n 116,\n 118,\n 119,\n 120,\n 121,\n 123,\n 124,\n 126,\n 128,\n 130,\n 132,\n 133,\n 134,\n 135,\n 136,\n 138,\n 139,\n 140,\n 142,\n 143,\n 144,\n 146,\n 148,\n 149,\n 150,\n 152,\n 154,\n 155,\n 156,\n 157,\n 158,\n 160,\n 161,\n 162,\n 164,\n 166,\n 167,\n 168,\n 169,\n 170,\n 171,\n 172,\n 173,\n 174,\n 176,\n 177,\n 178,\n 180,\n 182,\n 183,\n 184,\n 186,\n 187,\n 188,\n 190,\n 192,\n 194,\n 195,\n 196,\n 197,\n 198,\n 200,\n 201,\n 202,\n 203,\n 204,\n 205,\n 206,\n 208,\n 209,\n 210,\n 212,\n 214,\n 216,\n 217,\n 218,\n 219,\n 220,\n 221,\n 222,\n 224,\n 226,\n 227,\n 228,\n 230,\n 231,\n 232,\n 234,\n 236,\n 237,\n 238,\n 240,\n 242,\n 243,\n 244,\n 245,\n 246,\n 248,\n 249,\n 250,\n 252,\n 254,\n 256,\n 258,\n 259,\n 260,\n 262,\n 263,\n 264,\n 266,\n 267,\n 268,\n 269,\n 270,\n 271,\n 272,\n 273,\n 274,\n 275,\n 276,\n 277,\n 278,\n 280,\n 281,\n 282,\n 283,\n 284,\n 286,\n 287,\n 288,\n 290,\n 292,\n 294,\n 295,\n 296,\n 298,\n 299,\n 300,\n 301,\n 302,\n 304,\n 305,\n 306,\n 308,\n 310,\n 311,\n 312,\n 314,\n 316,\n 317,\n 318,\n 320,\n 321,\n 322,\n 324,\n 325,\n 326,\n 327,\n 328,\n 330,\n 331,\n 332,\n 334,\n 335,\n 336,\n 337,\n 338,\n 340,\n 342,\n 344,\n 346,\n 347,\n 348,\n 349,\n 350,\n 352,\n 354,\n 355,\n 356,\n 358,\n 360,\n 362,\n 364,\n 366,\n 368,\n 370,\n 371,\n 372,\n 373,\n 375,\n 376,\n 378,\n 379,\n 380,\n 382,\n 383,\n 384,\n 385,\n 386,\n 388,\n 389,\n 390,\n 392,\n 393,\n 394,\n 396,\n 398,\n 400,\n 402,\n 403,\n 404,\n 405,\n 406,\n 408,\n 410,\n 412,\n 413,\n 414,\n 415,\n 416,\n 418,\n 419,\n 420,\n 422,\n 424,\n 425,\n 426,\n 427,\n 428,\n 430,\n 431,\n 432,\n 434,\n 436,\n 438,\n 439,\n 440,\n 442,\n 444,\n 445,\n 446,\n 448,\n 449,\n 450,\n 451,\n 452,\n 454,\n 456,\n 457,\n 458,\n 460,\n 461,\n 462,\n 464,\n 466,\n 468,\n 470,\n 471,\n 472,\n 473,\n 474,\n 476,\n 477,\n 478,\n 480,\n 482,\n 484,\n 486,\n 487,\n 488,\n 489,\n 490,\n 491,\n 492,\n 494,\n 495,\n 498,\n 499,\n 500,\n 501,\n 502,\n 504,\n 505,\n 506,\n 508,\n 509,\n 510,\n 511,\n 512,\n 514,\n 516,\n 517,\n 518,\n 520,\n 522,\n 524,\n 525,\n 526,\n 527,\n 528,\n 530,\n 532,\n 533,\n 534,\n 535,\n 538,\n 540,\n 542,\n 543,\n 546,\n 547,\n 548,\n 549,\n 550,\n 552,\n 553,\n 554,\n 556,\n 558,\n 560,\n 561,\n 562,\n 564,\n 566,\n 568,\n 570,\n 572,\n 576,\n 577,\n 578,\n 579,\n 580,\n 582,\n 584,\n 585,\n 586,\n 588,\n 589,\n 590,\n 592,\n 594,\n 595,\n 596,\n 597,\n 598,\n 599,\n 600,\n 601,\n 602,\n 603,\n 604,\n 605,\n 606,\n 608,\n 609,\n 610,\n 611,\n 612,\n 613,\n 614,\n 616,\n 618,\n 619,\n 620,\n 622,\n 623,\n 624,\n 626,\n 628,\n 629,\n 630,\n 632,\n 634,\n 636,\n 637,\n 638,\n 640,\n 641,\n 642,\n 644,\n 646,\n 647,\n 648,\n 649,\n 650,\n 652,\n 653,\n 654,\n 656,\n 658,\n 659,\n 660,\n 661,\n 662,\n 663,\n 664,\n 666,\n 667,\n 668,\n 669,\n 670,\n 672,\n 674,\n 675,\n 676,\n 678,\n 680,\n 682,\n 683,\n 684,\n 685,\n 686,\n 688,\n 690,\n 691,\n 692,\n 693,\n 694,\n 696,\n 697,\n 698,\n 699,\n 794,\n 919,\n 1168,\n 1358,\n 1367,\n 1483,\n 1582,\n 1721,\n 2194,\n 2366,\n 2386,\n 2476,\n 2704,\n 2727,\n 2944,\n 2961,\n 3034,\n 3100,\n 3116,\n 3184,\n 3394,\n 3483,\n 3666,\n 3784,\n 3937,\n 4030,\n 4186,\n 4220,\n 4298,\n 4319,\n 4390,\n 4506,\n 4531,\n 4732,\n 4873,\n 4945]"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts_path = os.path.join(root_path, \"data\", \"generated\", dataset, \"script_with_cot_vars_first\")\n",
    "sample_indices = []\n",
    "for script_file in os.listdir(scripts_path):\n",
    "    if script_file.endswith(\".py\"):\n",
    "        with open(os.path.join(scripts_path, script_file), 'r') as f:\n",
    "            idx = int(script_file.split(\".\")[0].split(\"_\")[-1])\n",
    "            lines = f.readlines()\n",
    "            inputs = \"\\n\".join(lines[:3]).strip()\n",
    "            # script = \"\\n\".join(lines)\n",
    "            if \"more than\" in inputs or \"less than\" in inputs:\n",
    "                sample_indices.append(idx)\n",
    "sorted(sample_indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "130"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_with_quantifier = [idx for idx in misclassified_samples_indices if idx in sample_indices]\n",
    "len(misclassified_with_quantifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 7,\n 13,\n 15,\n 21,\n 29,\n 35,\n 39,\n 47,\n 55,\n 57,\n 67,\n 68,\n 73,\n 93,\n 96,\n 97,\n 99,\n 101,\n 103,\n 111,\n 113,\n 119,\n 123,\n 124,\n 126,\n 133,\n 135,\n 143,\n 149,\n 155,\n 161,\n 171,\n 173,\n 177,\n 183,\n 190,\n 195,\n 197,\n 203,\n 205,\n 209,\n 217,\n 221,\n 227,\n 237,\n 243,\n 249,\n 259,\n 267,\n 269,\n 271,\n 273,\n 281,\n 283,\n 287,\n 295,\n 311,\n 321,\n 325,\n 327,\n 331,\n 335,\n 337,\n 340,\n 347,\n 368,\n 371,\n 373,\n 383,\n 385,\n 389,\n 392,\n 393,\n 405,\n 415,\n 427,\n 431,\n 439,\n 451,\n 452,\n 473,\n 477,\n 489,\n 491,\n 495,\n 499,\n 501,\n 505,\n 506,\n 509,\n 511,\n 525,\n 527,\n 533,\n 549,\n 577,\n 579,\n 585,\n 589,\n 595,\n 598,\n 601,\n 602,\n 605,\n 611,\n 613,\n 623,\n 629,\n 641,\n 647,\n 649,\n 653,\n 661,\n 663,\n 669,\n 680,\n 683,\n 685,\n 691,\n 693,\n 699,\n 1168,\n 1483,\n 2386,\n 2727,\n 3937,\n 4319,\n 4873,\n 4945]"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified_with_quantifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWPNLI\n",
      "w-F1: 0.9584\n",
      "RedditNLI\n",
      "w-F1: 0.7085\n",
      "StressTest\n",
      "w-F1: 0.6705\n",
      "RTE_Quant\n",
      "w-F1: 0.8457\n",
      "NewsNLI\n",
      "w-F1: 0.7265\n",
      "9036\n",
      "EQUATE\n",
      "0.704\n"
     ]
    }
   ],
   "source": [
    "root_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "equate = pd.DataFrame()\n",
    "\n",
    "for dataset in [\"AWPNLI\", \"RedditNLI\", \"StressTest\", \"RTE_Quant\", \"NewsNLI\"]:\n",
    "    print(dataset)\n",
    "    results_path = os.path.join(root_path, \"data\", \"equate_labelled\", f\"{dataset}_phase2.csv\")\n",
    "    df = pd.read_csv(results_path)\n",
    "    # print(df.shape[0])\n",
    "    if dataset in [\"RTE_Quant\", \"NewsNLI\"]:\n",
    "        # Creating masks based on conditions\n",
    "        convert_contradiction_to_neutral_mask = df[\"generated_label\"] == \"contradiction\"\n",
    "        # Correctly assigning a new value using the combined mask with .loc\n",
    "        df.loc[convert_contradiction_to_neutral_mask, \"generated_label\"] = \"neutral\"\n",
    "    # print(df[df[\"golden_label\"] == df[\"generated_label\"]].shape[0])\n",
    "    # print(\"Acc:\", round(accuracy_score(df[\"golden_label\"], df[\"generated_label\"]), 3))\n",
    "    print(\"w-F1:\", round(f1_score(df[\"golden_label\"], df[\"generated_label\"], average=\"micro\"), 4))\n",
    "    equate = pd.concat([equate, df], ignore_index=True)\n",
    "\n",
    "print(equate.shape[0])\n",
    "print(\"EQUATE\")\n",
    "print(round(accuracy_score(equate[\"golden_label\"], equate[\"generated_label\"]), 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "6358"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "692+175+4658+137+696"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "6358"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equate[equate[\"golden_label\"] == equate[\"generated_label\"]].shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioanamazilu/PycharmProjects/quant_nli/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7052759676093809"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(equate[\"golden_label\"], equate[\"generated_label\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
