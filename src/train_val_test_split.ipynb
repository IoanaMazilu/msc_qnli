{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EXTRACT SAMPLES FROM LILA (they use Task 7 from NumGLUE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "lila_path = os.path.join(root_path, \"data\", \"lila\", \"all\", \"NumGLUE_Type_7_crowdsourced.json\")\n",
    "\n",
    "with open(lila_path, 'r') as f:\n",
    "    lila_equate = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['Source', 'Categories', 'Instances', 'Metadata'])"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_equate.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "lila_equate = lila_equate[\"Instances\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "6325"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lila_equate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['Input', 'Output Program', 'Output Answer', 'split'])"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_equate[0].keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "' \"statement 1\": In a deck of less than 72 cards , how many ways are there to select 13 Spade and 13 heart cards without repetition ?, \"statement 2\" :In a deck of 52 cards , how many ways are there to select 13 Spade and 13 heart cards without repetition ?, \"options: \" Entailment or contradiction or neutral?'"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_equate[0][\"Input\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "\"RajeshHaveQuestionsS1 = 41 \\nRajeshHaveQuestionsS2 = 31\\nif RajeshHaveQuestionsS1 is None or RajeshHaveQuestionsS2 is None:\\n   print('neutral')\\nelif RajeshHaveQuestionsS1==RajeshHaveQuestionsS2:\\n      print('Entailment')\\nelif RajeshHaveQuestionsS1!=RajeshHaveQuestionsS2:\\n     print('contradiction')\""
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_equate[1][\"Output Program\"][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "train, val, test = [], [], []\n",
    "for instance in lila_equate:\n",
    "    new_instance = dict()\n",
    "    inputs = instance[\"Input\"]\n",
    "    premise_hypothesis = inputs.split(\", \\\"statement 2\\\" :\")\n",
    "    try:\n",
    "        premise, hypothesis = premise_hypothesis[0], premise_hypothesis[1]\n",
    "        premise = premise.split(\"\\\"statement 1\\\": \")[-1]\n",
    "        hypothesis = hypothesis.split(\", \\\"options: \\\"\")[0]\n",
    "        new_instance.update({\"premise\": premise,\n",
    "                             \"hypothesis\": hypothesis,\n",
    "                             \"lila_label\": instance[\"Output Answer\"][0],\n",
    "                             \"lila_script\": instance[\"Output Program\"][0]})\n",
    "        split = instance[\"split\"]\n",
    "        if split == \"train\":\n",
    "            train.append(new_instance)\n",
    "        elif split == \"dev\":\n",
    "            val.append(new_instance)\n",
    "        else:\n",
    "            test.append(new_instance)\n",
    "    except IndexError:\n",
    "        print(f\"ERROR extracting inputs:\\n{inputs}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4302 806 1217\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(val), len(test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text: str):\n",
    "    return re.sub(r'\\s+', ' ', text.lower().replace(\"\\n\", \"\")).strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             premise  \\\n0  In a deck of less than 72 cards , how many way...   \n1  If out of 41 questions solved by Rajesh 37 que...   \n2  Alice drives at a constant speed of 30 km per ...   \n3               Mary is 22 years younger than Albert   \n4  Assuming that Karen drives at an average speed...   \n\n                                          hypothesis     lila_label  \\\n0  In a deck of 52 cards , how many ways are ther...        neutral   \n1  If out of 31 questions solved by Rajesh 37 que...  contradiction   \n2  Alice drives at a constant speed of 20 km per ...  contradiction   \n3               Mary is 72 years younger than Albert  contradiction   \n4  Assuming that Karen drives at an average speed...        neutral   \n\n                                         lila_script  \n0  DeckOfCardStatement1= None \\nDeckOfCardStateme...  \n1  RajeshHaveQuestionsS1 = 41 \\nRajeshHaveQuestio...  \n2  DrivesSpeedS1 = 30\\nDrivesSpeedS2 = 20\\nif Dri...  \n3  AgeS1 = 22\\nAgeS2 = 72\\nif AgeS1 is None or Ag...  \n4  \\nDriveS2 = 60\\nDriveS1 = None\\nif DriveS1 is ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>lila_label</th>\n      <th>lila_script</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In a deck of less than 72 cards , how many way...</td>\n      <td>In a deck of 52 cards , how many ways are ther...</td>\n      <td>neutral</td>\n      <td>DeckOfCardStatement1= None \\nDeckOfCardStateme...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>If out of 41 questions solved by Rajesh 37 que...</td>\n      <td>If out of 31 questions solved by Rajesh 37 que...</td>\n      <td>contradiction</td>\n      <td>RajeshHaveQuestionsS1 = 41 \\nRajeshHaveQuestio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alice drives at a constant speed of 30 km per ...</td>\n      <td>Alice drives at a constant speed of 20 km per ...</td>\n      <td>contradiction</td>\n      <td>DrivesSpeedS1 = 30\\nDrivesSpeedS2 = 20\\nif Dri...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mary is 22 years younger than Albert</td>\n      <td>Mary is 72 years younger than Albert</td>\n      <td>contradiction</td>\n      <td>AgeS1 = 22\\nAgeS2 = 72\\nif AgeS1 is None or Ag...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Assuming that Karen drives at an average speed...</td>\n      <td>Assuming that Karen drives at an average speed...</td>\n      <td>neutral</td>\n      <td>\\nDriveS2 = 60\\nDriveS1 = None\\nif DriveS1 is ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_train = pd.DataFrame(train)\n",
    "lila_test = pd.DataFrame(test)\n",
    "lila_val = pd.DataFrame(val)\n",
    "lila_val.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "lila_val[\"lila_label\"] = lila_val[\"lila_label\"].apply(lambda label: label.lower())\n",
    "lila_val[\"lila_label\"] = lila_val[\"lila_label\"].apply(lambda label: label.lower())\n",
    "lila_val[\"lila_label\"] = lila_val[\"lila_label\"].apply(lambda label: label.lower())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "for col in [\"premise\", \"hypothesis\"]:\n",
    "    lila_train[col] = lila_train[col].apply(lambda text: clean_text(text))\n",
    "    lila_test[col] = lila_test[col].apply(lambda text: clean_text(text))\n",
    "    lila_val[col] = lila_val[col].apply(lambda text: clean_text(text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "lila_train = lila_train[~lila_train.duplicated(subset=['premise', 'hypothesis'])]\n",
    "lila_test = lila_test[~lila_test.duplicated(subset=['premise', 'hypothesis'])]\n",
    "lila_val = lila_val[~lila_val.duplicated(subset=['premise', 'hypothesis'])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4302 1217 806\n"
     ]
    }
   ],
   "source": [
    "print(lila_train.shape[0], lila_test.shape[0], lila_val.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save train-val-test splits from LILA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lila_train.to_csv(os.path.join(root_path, \"data\", \"lila\", \"lila_train.csv\"), index=False)\n",
    "lila_test.to_csv(os.path.join(root_path, \"data\", \"lila\", \"lila_test.csv\"), index=False)\n",
    "lila_val.to_csv(os.path.join(root_path, \"data\", \"lila\", \"lila_val.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check for duplicates accross the entire LILA data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "lila_all = []\n",
    "lila_all.extend(train)\n",
    "lila_all.extend(test)\n",
    "lila_all.extend(val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "6325"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_all_df = pd.DataFrame(lila_all)\n",
    "lila_all_df.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_all_df[lila_all_df.duplicated(subset=[\"premise\", \"hypothesis\"])].shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "for col in [\"premise\", \"hypothesis\"]:\n",
    "    lila_all_df[col] = lila_all_df[col].apply(lambda text: clean_text(text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_all_df[lila_all_df.duplicated(subset=[\"premise\", \"hypothesis\"])].shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge LILA samples with EQUATE samples per EQUATE dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "(4302, 4)"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lila_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######NewsNLI#######\n",
      "Total instances: 963\n",
      "Train: 562\n",
      "Test: 0\n",
      "Val: 0\n",
      "Train: lila_label\n",
      "Entailment    312\n",
      "neutral       250\n",
      "Name: count, dtype: int64\n",
      "Test: Series([], Name: count, dtype: int64)\n",
      "Val: Series([], Name: count, dtype: int64)\n",
      "#######RTE_Quant#######\n",
      "Total instances: 165\n",
      "Train: 103\n",
      "Test: 0\n",
      "Val: 0\n",
      "Train: lila_label\n",
      "neutral       52\n",
      "Entailment    51\n",
      "Name: count, dtype: int64\n",
      "Test: Series([], Name: count, dtype: int64)\n",
      "Val: Series([], Name: count, dtype: int64)\n",
      "#######RedditNLI#######\n",
      "Total instances: 247\n",
      "Train: 0\n",
      "Test: 0\n",
      "Val: 0\n",
      "Train: Series([], Name: count, dtype: int64)\n",
      "Test: Series([], Name: count, dtype: int64)\n",
      "Val: Series([], Name: count, dtype: int64)\n",
      "#######StressTest#######\n",
      "Total instances: 6947\n",
      "Train: 3112\n",
      "Test: 1217\n",
      "Val: 806\n",
      "Train: lila_label\n",
      "neutral          1049\n",
      "contradiction    1048\n",
      "Entailment       1015\n",
      "Name: count, dtype: int64\n",
      "Test: lila_label\n",
      "contradiction    466\n",
      "Entailment       382\n",
      "neutral          369\n",
      "Name: count, dtype: int64\n",
      "Val: lila_label\n",
      "contradiction    276\n",
      "neutral          275\n",
      "entailment       255\n",
      "Name: count, dtype: int64\n",
      "#######AWPNLI#######\n",
      "Total instances: 722\n",
      "Train: 525\n",
      "Test: 0\n",
      "Val: 0\n",
      "Train: lila_label\n",
      "Entailment       266\n",
      "contradiction    259\n",
      "Name: count, dtype: int64\n",
      "Test: Series([], Name: count, dtype: int64)\n",
      "Val: Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "from qnli_datasets import read_data\n",
    "\n",
    "datasets = [\"NewsNLI\", \"RTE_Quant\", \"RedditNLI\", \"StressTest\", \"AWPNLI\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"#######{dataset}#######\")\n",
    "    instances, _ = read_data(f\"{dataset}.jsonl\")\n",
    "    equate_df = pd.DataFrame(instances)\n",
    "    equate_df[\"sample_index\"] = equate_df.index\n",
    "    equate_df[\"premise\"] = equate_df[\"premise\"].apply(lambda text: clean_text(text))\n",
    "    equate_df[\"hypothesis\"] = equate_df[\"hypothesis\"].apply(lambda text: clean_text(text))\n",
    "    equate_df = equate_df[~equate_df.duplicated(subset=['premise', 'hypothesis'])]\n",
    "    print(f\"Total instances: {equate_df.shape[0]}\")\n",
    "    equate_lila_train = pd.merge(equate_df, lila_train, on=[\"premise\", \"hypothesis\"], how=\"inner\")\n",
    "    equate_lila_test = pd.merge(equate_df, lila_test, on=[\"premise\", \"hypothesis\"], how=\"inner\")\n",
    "    equate_lila_val = pd.merge(equate_df, lila_val, on=[\"premise\", \"hypothesis\"], how=\"inner\")\n",
    "    print(f\"Train: {equate_lila_train.shape[0]}\\nTest: {equate_lila_test.shape[0]}\\nVal: {equate_lila_val.shape[0]}\")\n",
    "    print(f\"Train: {equate_lila_train['lila_label'].value_counts()}\\nTest: {equate_lila_test['lila_label'].value_counts()}\\nVal: {equate_lila_val['lila_label'].value_counts()}\")\n",
    "    output_path = os.path.join(root_path, \"data\", \"lila-equate\", dataset)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    if equate_lila_train.shape[0] > 0:\n",
    "        equate_lila_train.to_csv(os.path.join(output_path, \"train.csv\"), index=False)\n",
    "    if equate_lila_test.shape[0] > 0:\n",
    "        equate_lila_test.to_csv(os.path.join(output_path, \"test.csv\"), index=False)\n",
    "    if equate_lila_val.shape[0] > 0:\n",
    "        equate_lila_val.to_csv(os.path.join(output_path, \"val.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def extract_completion(full_script: str):\n",
    "    \"\"\"\n",
    "    Extract only script from the script .py files (remove comments containing the premise, hypothesis and EQUATE label.\n",
    "    :param full_script: the script as saved in a .py file in `data/generated/[dataset]/gpt4`\n",
    "    :return: the script without the removed parts or np.nan for a missing script\n",
    "    \"\"\"\n",
    "    if full_script is None or full_script == \"-\" or pd.isna(full_script):\n",
    "        return np.nan\n",
    "    try:\n",
    "        lines = full_script.split(\"\\n\")\n",
    "    except AttributeError:\n",
    "        print(\"#############\", \"\\n\", full_script)\n",
    "    idx = 0\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.startswith(\"# Golden Label:\"):\n",
    "            break\n",
    "    return \"\\n\".join(lines[idx+3:-1])  # skip label and 2 blank lines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = \"StressTest\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[5699. 5700. 5701. 5702. 5703. 5704. 5705. 5706. 5707. 5959. 5960.]\n"
     ]
    },
    {
     "data": {
      "text/plain": "7596"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_csv(os.path.join(root_path, \"data\", \"equate\", f\"{dataset}.csv\"))\n",
    "labels_df = pd.read_csv(os.path.join(root_path, \"data\", \"generated\", dataset, \"gpt4\", \"random_sample_results_overview.csv\"))\n",
    "print(labels_df[labels_df[\"py_file_content\"]==\"-\"].shape[0])\n",
    "print(labels_df[labels_df[\"py_file_content\"]==\"-\"][\"sample_index\"].unique())\n",
    "labels_df[\"completion\"] = labels_df[\"py_file_content\"].apply(lambda full_script: extract_completion(full_script))\n",
    "merged_df = pd.merge(dataset_df, labels_df, on=\"sample_index\", how=\"left\")\n",
    "merged_df.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             premise  \\\n0  In 1956 Accardo won the Geneva Competition and...   \n1  David Golinkin is the editor or author of eigh...   \n2  David Golinkin is single-handedly responsible ...   \n3  During Reinsdorf 's 24 seasons as chairman of ...   \n4  During Reinsdorf 's 24 seasons as chairman of ...   \n\n                                          hypothesis       label  \\\n0                     Accardo composed 24 Caprices .     neutral   \n1              Golinkin has written eighteen books .     neutral   \n2  David Golinkin is the author of dozen of respo...     neutral   \n3  Reinsdorf was the chairman of the White Sox fo...  entailment   \n4          The White Sox have won 24 championships .     neutral   \n\n   sample_index                                         llm_answer  \\\n0             0  ```python\\ncaprices_premise = 24\\ncaprices_hyp...   \n1             1  ```python\\ntotal_books_premise = 18\\ntotal_boo...   \n2             2  ```python\\ndozens_responsa_premise = 24 # one ...   \n3             3  ```python\\nseasons_as_chairman_premise = 24\\ns...   \n4             4  ```python\\nseasons_as_chairman_premise = 24\\nd...   \n\n                                     py_file_content  \\\n0  \\n# Premise: In 1956 Accardo won the Geneva Co...   \n1  \\n# Premise: David Golinkin is the editor or a...   \n2  \\n# Premise: David Golinkin is single-handedly...   \n3  \\n# Premise: During Reinsdorf 's 24 seasons as...   \n4  \\n# Premise: During Reinsdorf 's 24 seasons as...   \n\n                                          completion  \n0  caprices_premise = 24\\ncaprices_hypothesis = 2...  \n1  total_books_premise = 18\\ntotal_books_hypothes...  \n2  dozens_responsa_premise = 24 # one dozen is 12...  \n3  seasons_as_chairman_premise = 24\\nseasons_as_c...  \n4  seasons_as_chairman_premise = 24\\ndivision_cha...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n      <th>sample_index</th>\n      <th>llm_answer</th>\n      <th>py_file_content</th>\n      <th>completion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In 1956 Accardo won the Geneva Competition and...</td>\n      <td>Accardo composed 24 Caprices .</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>```python\\ncaprices_premise = 24\\ncaprices_hyp...</td>\n      <td>\\n# Premise: In 1956 Accardo won the Geneva Co...</td>\n      <td>caprices_premise = 24\\ncaprices_hypothesis = 2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>David Golinkin is the editor or author of eigh...</td>\n      <td>Golinkin has written eighteen books .</td>\n      <td>neutral</td>\n      <td>1</td>\n      <td>```python\\ntotal_books_premise = 18\\ntotal_boo...</td>\n      <td>\\n# Premise: David Golinkin is the editor or a...</td>\n      <td>total_books_premise = 18\\ntotal_books_hypothes...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>David Golinkin is single-handedly responsible ...</td>\n      <td>David Golinkin is the author of dozen of respo...</td>\n      <td>neutral</td>\n      <td>2</td>\n      <td>```python\\ndozens_responsa_premise = 24 # one ...</td>\n      <td>\\n# Premise: David Golinkin is single-handedly...</td>\n      <td>dozens_responsa_premise = 24 # one dozen is 12...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>During Reinsdorf 's 24 seasons as chairman of ...</td>\n      <td>Reinsdorf was the chairman of the White Sox fo...</td>\n      <td>entailment</td>\n      <td>3</td>\n      <td>```python\\nseasons_as_chairman_premise = 24\\ns...</td>\n      <td>\\n# Premise: During Reinsdorf 's 24 seasons as...</td>\n      <td>seasons_as_chairman_premise = 24\\nseasons_as_c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>During Reinsdorf 's 24 seasons as chairman of ...</td>\n      <td>The White Sox have won 24 championships .</td>\n      <td>neutral</td>\n      <td>4</td>\n      <td>```python\\nseasons_as_chairman_premise = 24\\nd...</td>\n      <td>\\n# Premise: During Reinsdorf 's 24 seasons as...</td>\n      <td>seasons_as_chairman_premise = 24\\ndivision_cha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['premise', 'hypothesis', 'label', 'sample_index', 'llm_answer',\n       'py_file_content', 'completion'],\n      dtype='object')"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create train-test-val splits in a 70-20-10 ratio, ensuring the test split from LILA overlaps with our test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total after split:  7595\n",
      "Total before split:  7596\n",
      "5317 759 1520\n"
     ]
    }
   ],
   "source": [
    "ds_size = merged_df.shape[0]\n",
    "train_size, val_size, test_size = int(ds_size * 0.7), int(ds_size * 0.1), int(ds_size * 0.2)\n",
    "print(\"Total after split: \", train_size + val_size + test_size)\n",
    "print(\"Total before split: \", ds_size)\n",
    "extra = ds_size - (train_size + val_size + test_size)\n",
    "test_size += extra\n",
    "print(train_size, val_size, test_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LILA test size: 1217\n",
      "303\n"
     ]
    }
   ],
   "source": [
    "lila_test_indices = []\n",
    "try:\n",
    "    df = pd.read_csv(os.path.join(root_path, \"data\", \"lila-equate\", dataset, \"test.csv\"))\n",
    "    lila_test_indices = list(df[\"sample_index\"].unique())\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "data_for_split = merged_df[~merged_df[\"sample_index\"].isin(lila_test_indices)]  # which data we can use for further splitting\n",
    "\n",
    "print(f\"LILA test size: {len(lila_test_indices)}\")\n",
    "test_size = max(test_size, len(lila_test_indices))\n",
    "\n",
    "extra_samples_needed = test_size - len(lila_test_indices)\n",
    "print(extra_samples_needed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ratio: 0.04749960808904217\n"
     ]
    }
   ],
   "source": [
    "test_ratio = extra_samples_needed / data_for_split.shape[0]\n",
    "\n",
    "print(f\"test ratio: {test_ratio}\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dev, test = train_test_split(data_for_split, test_size=test_ratio, stratify=data_for_split[\"label\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "train, val = train_test_split(dev, test_size=val_size/dev.shape[0], stratify=dev[\"label\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5317 759 1520\n"
     ]
    }
   ],
   "source": [
    "if len(lila_test_indices) > 0:\n",
    "    lila_set = merged_df[merged_df[\"sample_index\"].isin(lila_test_indices)]\n",
    "    test = pd.concat([test, lila_set], ignore_index=True)\n",
    "print(train.shape[0], val.shape[0], test.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save out train-test-val splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(root_path, \"data\", \"finetuning\", dataset), exist_ok=True)\n",
    "train.to_csv(os.path.join(root_path, \"data\", \"finetuning\", dataset, \"train.csv\"))\n",
    "test.to_csv(os.path.join(root_path, \"data\", \"finetuning\", dataset, \"test.csv\"))\n",
    "val.to_csv(os.path.join(root_path, \"data\", \"finetuning\", dataset, \"val.csv\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add target label to the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate prompt and completion features, which will form the dataset for fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN set\n",
      "Samples with no generated script: 0, ([])\n",
      "Creating train file.\n",
      "TEST set\n",
      "Samples with no generated script: 0, ([])\n",
      "Creating test file.\n",
      "VAL set\n",
      "Samples with no generated script: 0, ([])\n",
      "Creating val file.\n"
     ]
    }
   ],
   "source": [
    "from prompts import format_prompt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# dataset = \"RTE_Quant\"   # can also use `dataset` variable set above\n",
    "\n",
    "for split in [\"train\", \"test\", \"val\"]:\n",
    "    print(f\"{split.upper()} set\")\n",
    "    df = pd.read_csv(os.path.join(root_path, \"data\", \"finetuning\", dataset, f\"{split}.csv\"))\n",
    "    missing_scripts = df[df[\"py_file_content\"] == \"-\"][\"sample_index\"]\n",
    "    print(f'Samples with no generated script: {missing_scripts.shape[0]}, ({missing_scripts.unique()})')\n",
    "    if missing_scripts.shape[0] == 0:\n",
    "        print(f\"Creating {split} file.\")\n",
    "        df[\"prompt\"] = df.apply(lambda row: format_prompt(dataset.lower().replace(\"_\", \"\"), {\"premise\": row[\"premise\"], \"hypothesis\": row[\"hypothesis\"]}), axis=1)\n",
    "        df[\"completion\"] = df[\"completion\"].apply(lambda completion: f\"```python\\n{completion}```\")\n",
    "        os.makedirs(os.path.join(root_path, \"data\", \"finetuning\", dataset, \"completion\"), exist_ok=True)\n",
    "        df[[\"completion\", \"prompt\"]].to_csv(os.path.join(root_path, \"data\", \"finetuning\", dataset, \"completion\", f\"{split}.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "'```python\\nboys_premise = 27.0\\ngirls_premise = 35.0\\nchildren_left_hypothesis = 8.0\\n\\ndef entailment_or_contradiction(boys_premise, girls_premise, children_left_hypothesis):\\n    # the hypothesis claims that there were 8 children left on the playground\\n    # according to the premise, each boy went back inside with a girl\\n    # so, the number of children left should be the difference between the number of girls and boys\\n    children_left_premise = girls_premise - boys_premise\\n    # check if the quantities in the premise and hypothesis are equal\\n    return children_left_premise == children_left_hypothesis\\n\\nprint(entailment_or_contradiction(boys_premise, girls_premise, children_left_hypothesis))\\n```'"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"completion\", \"prompt\"]].head(1)[\"completion\"][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# df[\"text\"] = df.apply(lambda row: f'{row[\"prompt\"]}\\n### Response:\\n```python\\n{row[\"completion\"]}```', axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# df[\"text\"].to_csv(os.path.join(root_path, \"data\", \"finetuning\", \"AWPNLI\", \"text\", \"val_text.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "\"### Instruction:\\nYou need to reason about weather a hypothesis entails or contradicts a premise, by generating Python scripts. The scripts should classify the relation between the hypothesis and premise based on the quantitative and textual information mentioned in them. All the quantities and textual details in the hypothesis should be entailed by the information in the premise. First, manually extract all the individual quantities from both of the inputs, as valid numbers. Use the variable name to describe what the quantity measures, based on the context. Then, define a Python function that takes the extracted quantities as arguments. Within the function, use these quantities to perform computations based on the context of the premise and hypothesis. Finally, compare the resulting variables to determine the relationship. If the comparison indicates entailment, return True; for contradiction return False. Remember to include brief comments in the script to explain each step of the reasoning process. To illustrate, consider the following examples:\\nSTART_EXAMPLE\\nPremise: Yesterday I learned 35 verbs and 5 nouns in the morning and 10 verbs in the evening.\\nHypothesis: I learned 5 nouns and less than fifty verbs yesterday.\\nAnswer:\\n```python\\nverbs_morning_premise = 35\\nverbs_evening_premise = 10\\nnouns_premise = 5\\nmax_verbs_hypothesis = 50 \\nnouns_hypothesis = 5\\n\\ndef entailment_or_contradiction(verbs_morning_premise, verbs_evening_premise, nouns_premise, max_verbs_hypothesis, nouns_hypothesis):\\n    # the hypothesis talks about the number of learned nouns and verbs, which are also referenced in the premise\\n    # find the total number of verbs learned from the premise \\n    total_verbs_premise = verbs_morning_premise + verbs_evening_premise\\n    # check if the total verbs form the hypothesis is more than 'verbs_evening_premise' and if the number of nouns is equal between the premise and hypothesis\\n    return max_verbs_hypothesis > total_verbs_premise and nouns_premise == nouns_hypothesis\\n\\nprint(entailment_or_contradiction(verbs_morning_premise, verbs_evening_premise, nouns_premise, max_verbs_hypothesis, nouns_hypothesis))\\n```\\nEND_EXAMPLE\\n\\nSTART_EXAMPLE\\nPremise: She bought 10 crayons and received 5 more from her desk mate.\\nHypothesis: She has 10 crayons in total.\\nAnswer:\\n```python\\nbought_crayons_premise = 10\\nreceived_crayons_premise = 5\\ntotal_crayons_hypothesis = 12\\n\\ndef entailment_or_contradiction(bought_crayons_premise, received_crayons_premise, total_crayons_hypothesis):\\n    # the entity in the hypothesis can be computed from the entities in the premise\\n    total_crayons_premise = bought_crayons_premise + received_crayons_premise\\n    # check if 'total_crayons_hypothesis' entails the quantity deduced from the premise, so if they are equal\\n    return total_crayons_premise == total_crayons_hypothesis:\\n\\nprint(entailment_or_contradiction(bought_crayons_premise, received_crayons_premise, total_crayons_hypothesis))\\n```\\nEND_EXAMPLE\\n### Input:\\nPremise: Sally had 760.0 quarters in her bank  and she spent 418.0 of her quarters \\nHypothesis: She has 342.0 quarters now\\n### Response:\\n```python\\nquarters_beginning_premise = 760.0\\nquarters_spent_premise = 418.0\\nquarters_remaining_hypothesis = 342.0\\n\\ndef entailment_or_contradiction(quarters_beginning_premise, quarters_spent_premise, quarters_remaining_hypothesis):\\n    # the hypothesis talks about the remaining quarters, which can be computed from the premise\\n    quarters_remaining_premise = quarters_beginning_premise - quarters_spent_premise\\n    # check if 'quarters_remaining_hypothesis' entails the quantity deduced from the premise, so if they are equal\\n    return quarters_remaining_premise == quarters_remaining_hypothesis\\n\\nprint(entailment_or_contradiction(quarters_beginning_premise, quarters_spent_premise, quarters_remaining_hypothesis))\\n```\""
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"text\"][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
