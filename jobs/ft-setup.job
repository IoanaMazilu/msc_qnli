#!/bin/bash

#SBATCH --partition=gpu
#SBARCH --nodes=1
#SBATCH --gpus=1
#SBATCH --job-name=test-ft-setup
#SBATCH --time=00:40:00
#SBATCH --output=slurm_output_%A.out
#SBATCH --mail-type=ALL
#SBATCH --mail-user=ioana.mazilu@student.uva.nl

module purge
module load 2022
module load Python/3.10.4-GCCcore-11.3.0

mkdir -p "$TMPDIR"/output/awpnli_ft/
mkdir -p "$TMPDIR"/input/completion/

cd $HOME/qnli/quant_nli
cp -r data/finetuning/AWPNLI/completion/train.csv "$TMPDIR"/input/completion/
cp -r data/finetuning/AWPNLI/completion/val.csv "$TMPDIR"/input/completion/

cd $HOME/qnli/quant_nli/src/ft
export HF_TOKEN="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"
export HF_HOME="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"
python finetuning_normal.py --output-path "$TMPDIR" --input-path "$TMPDIR" --experiment awpnli_ft --target_model awpnli_llama2-ft

mkdir -p $HOME/qnli/quant_nli/results/awpnli_ft/
cd "$TMPDIR"/output
cp -r awpnli_ft/ $HOME/qnli/quant_nli/results/awpnli_ft/
